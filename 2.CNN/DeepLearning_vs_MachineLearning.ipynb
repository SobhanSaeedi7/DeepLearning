{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XGMkz-uVdtw5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP(input_dataset):\n",
        "  if input_dataset == 'mnist':\n",
        "    dataset = tf.keras.datasets.mnist\n",
        "  elif input_dataset == 'fashion_mnist':\n",
        "    dataset = tf.keras.datasets.fashion_mnist\n",
        "  elif input_dataset == 'cifar10':\n",
        "    dataset = tf.keras.datasets.cifar10\n",
        "  elif input_dataset == 'cifar100':\n",
        "    dataset = tf.keras.datasets.cifar100\n",
        "  else:\n",
        "    print('Dataset is not defined!')\n",
        "    return ..., ...\n",
        "\n",
        "  if input_dataset == 'cifar100':\n",
        "    output_layer = 100\n",
        "  else:\n",
        "    output_layer = 10\n",
        "\n",
        "  (x_train, y_train),(x_test, y_test) = dataset.load_data()\n",
        "  x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(x_train[0].shape)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(output_layer, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.fit(x_train, y_train, epochs=5)\n",
        "  loss, accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "  return loss, accuracy"
      ],
      "metadata": {
        "id": "BnHy8u8miOxN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_MLP(input_dataset):\n",
        "\n",
        "  if input_dataset == 'mnist':\n",
        "    dataset = tf.keras.datasets.mnist\n",
        "  elif input_dataset == 'fashion_mnist':\n",
        "    dataset = tf.keras.datasets.fashion_mnist\n",
        "  elif input_dataset == 'cifar10':\n",
        "    dataset = tf.keras.datasets.cifar10\n",
        "  elif input_dataset == 'cifar100':\n",
        "    dataset = tf.keras.datasets.cifar100\n",
        "  else:\n",
        "    print('Dataset is not defined!')\n",
        "    return ..., ...\n",
        "\n",
        "  if input_dataset == 'cifar100':\n",
        "    output_layer = 100\n",
        "  else:\n",
        "    output_layer = 10\n",
        "\n",
        "  (x_train, y_train),(x_test, y_test) = dataset.load_data()\n",
        "  x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "  if input_dataset == 'mnist' or input_dataset == 'fashion_mnist':\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "      # Deep Learning\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)), #26\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'), #24\n",
        "      tf.keras.layers.MaxPooling2D(), #12\n",
        "      tf.keras.layers.Conv2D(16, (3,3), activation='relu'), #10\n",
        "      tf.keras.layers.Conv2D(8, (3,3), activation='relu'), #8\n",
        "      tf.keras.layers.MaxPooling2D(), #4\n",
        "      tf.keras.layers.Conv2D(4, (3,3), activation='relu'), #2\n",
        "      tf.keras.layers.Flatten(input_shape=(2, 2)),\n",
        "      # Machine Learning\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(output_layer, activation='softmax')])\n",
        "\n",
        "\n",
        "  elif input_dataset == 'cifar10' or input_dataset == 'cifar100':\n",
        "    model = tf.keras.models.Sequential([\n",
        "      # Deep Learning\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)), #30\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'), #28\n",
        "      tf.keras.layers.MaxPooling2D(), #14\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'), #12\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'), #10\n",
        "      tf.keras.layers.MaxPooling2D(), #5\n",
        "      tf.keras.layers.Flatten(input_shape=(2, 2)),\n",
        "      # Machine Learning\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(output_layer, activation='softmax')])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.fit(x_train, y_train, epochs=10)\n",
        "  loss, accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "  return loss, accuracy"
      ],
      "metadata": {
        "id": "iF86QyA_TBxB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ['mnist', 'fashion_mnist', 'cifar10', 'cifar100']\n",
        "MLP_results = []\n",
        "CNN_MLP_results = []"
      ],
      "metadata": {
        "id": "DY4nA-FMqyKd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in datasets:\n",
        "  loss, accuracy = MLP(dataset)\n",
        "  result = {dataset+'_loss':loss, dataset+'_accuracy':accuracy}\n",
        "  MLP_results.append(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjjE4kF4rb7f",
        "outputId": "b39fbe6b-a07e-4a59-e62a-ebbfc1225cc4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2911 - accuracy: 0.9161\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1435 - accuracy: 0.9574\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1078 - accuracy: 0.9675\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9732\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0769 - accuracy: 0.9760\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9778\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5292 - accuracy: 0.8137\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3986 - accuracy: 0.8554\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3684 - accuracy: 0.8654\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3473 - accuracy: 0.8721\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3328 - accuracy: 0.8773\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8683\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 2.0455 - accuracy: 0.2303\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9664 - accuracy: 0.2640\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.9409 - accuracy: 0.2776\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9251 - accuracy: 0.2846\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9068 - accuracy: 0.2951\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.7855 - accuracy: 0.3579\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 4.6080 - accuracy: 0.0088\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 4.5568 - accuracy: 0.0135\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 4.4771 - accuracy: 0.0192\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 4.4595 - accuracy: 0.0203\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 4.4468 - accuracy: 0.0219\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 4.3879 - accuracy: 0.0267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in datasets:\n",
        "  loss, accuracy = CNN_MLP(dataset)\n",
        "  result = {dataset+'_loss':loss, dataset+'_accuracy':accuracy}\n",
        "  CNN_MLP_results.append(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF0mLFqMTTAk",
        "outputId": "5b3b64df-c515-4b2c-be3e-9be35c98d341"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 14s 5ms/step - loss: 0.3052 - accuracy: 0.9029\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1024 - accuracy: 0.9689\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0795 - accuracy: 0.9763\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0665 - accuracy: 0.9799\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0591 - accuracy: 0.9814\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0525 - accuracy: 0.9841\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0463 - accuracy: 0.9854\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0444 - accuracy: 0.9865\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0425 - accuracy: 0.9870\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0372 - accuracy: 0.9879\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.9877\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 12s 5ms/step - loss: 0.7284 - accuracy: 0.7268\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4492 - accuracy: 0.8337\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3984 - accuracy: 0.8529\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3646 - accuracy: 0.8647\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3434 - accuracy: 0.8713\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3263 - accuracy: 0.8788\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3091 - accuracy: 0.8857\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2977 - accuracy: 0.8889\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2886 - accuracy: 0.8927\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2804 - accuracy: 0.8963\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3058 - accuracy: 0.8904\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 12s 6ms/step - loss: 1.5069 - accuracy: 0.4483\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0732 - accuracy: 0.6207\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8899 - accuracy: 0.6864\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7827 - accuracy: 0.7282\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7052 - accuracy: 0.7548\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6414 - accuracy: 0.7752\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5775 - accuracy: 0.7964\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5288 - accuracy: 0.8116\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4815 - accuracy: 0.8303\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4314 - accuracy: 0.8474\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8609 - accuracy: 0.7374\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 11s 6ms/step - loss: 4.0141 - accuracy: 0.0811\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 3.3867 - accuracy: 0.1807\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 3.0722 - accuracy: 0.2426\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.8522 - accuracy: 0.2864\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.6760 - accuracy: 0.3183\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 2.5302 - accuracy: 0.3458\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 2.4183 - accuracy: 0.3697\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3121 - accuracy: 0.3928\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2163 - accuracy: 0.4112\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1260 - accuracy: 0.4279\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6079 - accuracy: 0.3593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjcK2sYnsvH8",
        "outputId": "709a147a-f576-460b-b98d-8745f39e8c7b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'mnist_loss': 0.07027990370988846, 'mnist_accuracy': 0.9778000116348267},\n",
              " {'fashion_mnist_loss': 0.3656897246837616,\n",
              "  'fashion_mnist_accuracy': 0.8683000206947327},\n",
              " {'cifar10_loss': 1.7855206727981567, 'cifar10_accuracy': 0.3578999936580658},\n",
              " {'cifar100_loss': 4.387901306152344,\n",
              "  'cifar100_accuracy': 0.02669999934732914}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_MLP_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7tUVAcuWrgK",
        "outputId": "fbf77593-59ce-43f2-8c38-40c430905008"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'mnist_loss': 0.035379815846681595, 'mnist_accuracy': 0.9876999855041504},\n",
              " {'fashion_mnist_loss': 0.30581167340278625,\n",
              "  'fashion_mnist_accuracy': 0.8903999924659729},\n",
              " {'cifar10_loss': 0.8609036207199097, 'cifar10_accuracy': 0.7373999953269958},\n",
              " {'cifar100_loss': 2.607935667037964,\n",
              "  'cifar100_accuracy': 0.35929998755455017}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}